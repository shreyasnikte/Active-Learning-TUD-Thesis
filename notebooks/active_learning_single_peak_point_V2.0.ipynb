{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning for dToU tariff policy\n",
    "## Minimizing the cost of labelling\n",
    "This notebook contains the simple active learning model of prediction of peak load shaving. The *Simulator* class contains the data point generation code, which ideally generates a new data point following given conditions (currently, day-of-week and season). The *activeLearner* class is a active learning loop which is simulating the real world experimentation. The detailed information about each class is provided above each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# from pandas.tools.plotting import autocorrelation_plot\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import Title\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "from tqdm import tqdm            #for .py version\n",
    "# from tqdm import tqdm_notebook as tqdm     # for .ipynb version\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters dictionary\n",
    "\n",
    "The following cell contains the single list of main parameters used in the python notebook. The following `param` variable is called in all the classes and passed to functions by self object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dict 'params' consists of all the parameters used in the simulation software for ease of alteration\n",
    "params = {\n",
    "#         Set the regression model related parameters\n",
    "          'train_start_dt':'2013-01',\n",
    "          'train_stop_dt':'2013-12',\n",
    "          'y_variable': 'trial_d',\n",
    "          'X_variables':['trial_n', 'low', 'normal', 'high', 'WIND_DIRECTION', \n",
    "                         'WIND_SPEED', 'VISIBILITY', 'MSL_PRESSURE',\n",
    "                         'AIR_TEMPERATURE', 'DEWPOINT', 'WETB_TEMP', \n",
    "                         'STN_PRES', 'WMO_HR_SUN_DUR', 'hour', 'day'],\n",
    "    \n",
    "#         Set XGBoost regression parameters (for consumption model)\n",
    "          'n_estimators': 2000,\n",
    "          'early_stopping_rounds': 50,  #stop if 50 consequent rounds without decrease of error\n",
    "          'verbose': False,             # Change verbose to True if you want to see it train\n",
    "          'nthread': 4,\n",
    "    \n",
    "#         Set simulator parameters to default values\n",
    "          'season': 3,\n",
    "          'day_of_week': 3,\n",
    "          'special_event': 0,\n",
    "          'tariff_policy':[],\n",
    "    \n",
    "#         Set Occupant behaviour dynamics\n",
    "          'active_users': 0.1,#.5,     # Set the % of users who are willing to engage in the experiments\n",
    "          'avail_users': 0.1,#.5,       # Set the % of users who will be available to participate in specific experiment\n",
    "          'user_latency': 0,         # Set the values which correspond to real life participation delay for users \n",
    "          'frac_users_exp':1,      # Fraction of users selected for a particular trial\n",
    "          \n",
    "#         Set parameters for active learning\n",
    "          'total_iterations':5,\n",
    "          'total_experiments':1000,#100, #Total number of experiments allowed per trial\n",
    "          'init_samples': 10,#50,      # Set the initial random samples to be chosen\n",
    "          'test_size':.3,           # Set test data size for splitting data in train-test\n",
    "          'X_var_activeL':['dow', \n",
    "                           'season', \n",
    "                           'hod', \n",
    "                           'AIR_TEMPERATURE', \n",
    "                           'DEWPOINT', \n",
    "                           'MSL_PRESSURE', \n",
    "                           'STN_PRES',\n",
    "                           'VISIBILITY', \n",
    "                           'WETB_TEMP',\n",
    "                           'WIND_DIRECTION',\n",
    "                           'WIND_SPEED',\n",
    "                           'WMO_HR_SUN_DUR',\n",
    "                           'hod', \n",
    "                           'month'],\n",
    "    \n",
    "          'y_var_activeL':'expected'\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumption model\n",
    "\n",
    "The following model consists the aggregate energy consumption model of the LCL users. The model tends to generalize the predictions, therefore it is not used for generation of new data for random timestamps. Instead, in future, it can be used to add the weather effect in the user response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsumptionModel(object):\n",
    "    def __init__(self, df, params):\n",
    "        self.df = df\n",
    "        self.params = params\n",
    "#         some variables\n",
    "\n",
    "    def prep_data(self):\n",
    "        self.df = self.df.dropna().copy()\n",
    "        one_hot= pd.get_dummies(self.df['tariff'])\n",
    "        one_hot_renamed = one_hot.rename(index=str, columns={0.0399:'low', 0.1176:'normal', 0.672:'high'}) \n",
    "        self.df = self.df.join(one_hot_renamed).drop('tariff', axis=1)\n",
    "        \n",
    "        self.df[\"hour\"] = self.df.index.hour\n",
    "        self.df[\"day\"] = self.df.index.day\n",
    "        self.df[\"month\"] = self.df.index.month\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "#         Complete the xgboost model on 2013 data\n",
    "        self.X_train = self.df.loc[self.params[\"train_start_dt\"]:self.params[\"train_stop_dt\"],self.params[\"X_variables\"]]\n",
    "        self.y_train = self.df.loc[self.params[\"train_start_dt\"]:self.params[\"train_stop_dt\"],self.params[\"y_variable\"]]\n",
    "        self.X_test = self.df.loc[self.params[\"train_stop_dt\"]:,self.params[\"X_variables\"]]\n",
    "        self.y_test = self.df.loc[self.params[\"train_stop_dt\"]:,self.params[\"y_variable\"]]\n",
    "\n",
    "        self.xg_reg = xgb.XGBRegressor(n_estimators=self.params['n_estimators'], nthread = self.params[\"nthread\"])\n",
    "        self.xg_reg.fit(self.X_train, self.y_train,\n",
    "                        eval_set=[(self.X_train, self.y_train), (self.X_test, self.y_test)],\n",
    "                        early_stopping_rounds = self.params[\"early_stopping_rounds\"],\n",
    "                        verbose = self.params[\"verbose\"])\n",
    "\n",
    "#         Get feature importance chart\n",
    "        return xgb.plot_importance(self.xg_reg, height=0.9) # Plot feature importance\n",
    "      \n",
    "\n",
    "    def test(self, X_test, tariff):\n",
    "#         test the data points. Get the predictions\n",
    "        self.preds = self.xg_reg.predict(X_test)\n",
    "        pass\n",
    "        \n",
    "\n",
    "    \n",
    "    def entropy(self):\n",
    "#         get entropy of each data point nad return the entropy dataframe\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator\n",
    "This class creates a new data point on request. The new datapoint can be constrained to some calendar parameters like day-of-week and season-of-year. The following cell randomly selects the date index which follows the input constraints and generates a 'new' datapoint by aggregating the data of multiple LCL energy users.\n",
    "\n",
    "Also the tariff policy and user response for that particular day is decided by modelling stochastic behaviour of users. Therefore, each user's response is calculated individually by considering user latency into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    \n",
    "    \n",
    "    def __init__(self, df, df_weather, params):\n",
    "        self.params = params\n",
    "        self.df = df\n",
    "        self.df_weather = df_weather\n",
    "        active_users = int(len(df.columns)*self.params[\"active_users\"])   # get no. of active users from input percentage\n",
    "        self.active_users = random.sample(list(df.columns), active_users)\n",
    "        self.noisy_tariff = {}\n",
    "        self.spring = [3, 4, 5]\n",
    "        self.summer = [6, 7, 8]\n",
    "        self.autumn = [9, 10, 11]\n",
    "        self.winter = [1, 2, 12]\n",
    "\n",
    "\n",
    "    def select_day(self):\n",
    "#         Get user ids of participating users\n",
    "        self.fuzzy_participation()\n",
    "\n",
    "#         Select the season\n",
    "        if selectsample.params[\"season\"] == -1:\n",
    "            month = random.randrange(1,12)\n",
    "        elif selectsample.params[\"season\"] == 0:\n",
    "            month = random.choice(self.spring)\n",
    "        elif selectsample.params[\"season\"] == 1:\n",
    "            month = random.choice(self.summer)\n",
    "        elif selectsample.params[\"season\"] == 2:\n",
    "            month = random.choice(self.autumn)\n",
    "        elif selectsample.params[\"season\"] == 3:\n",
    "            month = random.choice(self.winter)\n",
    "\n",
    "#         Select the day of week\n",
    "        if selectsample.params[\"day_of_week\"] == -1:\n",
    "#             Select random day\n",
    "            dow = random.randrange(0,7)\n",
    "        else:\n",
    "            dow = selectsample.params[\"day_of_week\"] \n",
    "\n",
    "#         Select the random day from the entries which satisfy above conditions\n",
    "        shortlist = self.df.loc[(self.df.index.month == month) & (self.df.index.dayofweek == dow), :].index\n",
    "        \n",
    "#         day = random.choice(shortlist.day.values)\n",
    "#         year = random.choice(shortlist.year.values)\n",
    "        random_index = random.choice(shortlist)\n",
    "        timestamp = str(random_index.year)+\"-\"+str(random_index.month)+\"-\"+str(random_index.day)\n",
    "#         print(timestamp, \" Select day\")\n",
    "        self.sample = self.df.loc[timestamp,self.avail_users]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def random_day(self):\n",
    "#         Get user ids of participating users\n",
    "        self.fuzzy_participation()\n",
    "    \n",
    "#         Sample a random day timestamp\n",
    "        shortlist = self.df.sample(axis = 0).index\n",
    "#         day = random.choice(shortlist.day.values)\n",
    "#         month = random.choice(shortlist.month.values)\n",
    "#         year = random.choice(shortlist.year.values)\n",
    "        random_index = random.choice(shortlist)\n",
    "        self.timestamp = str(random_index.year)+\"-\"+str(random_index.month)+\"-\"+str(random_index.day)\n",
    "#         print(timestamp, \" Random day\")\n",
    "        self.sample = self.df.loc[self.timestamp,self.avail_users]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fuzzy_participation(self):\n",
    "        avail_users = int(len(self.active_users)*self.params[\"avail_users\"])\n",
    "        self.avail_users = random.sample(self.active_users, avail_users)\n",
    "    \n",
    "    \n",
    "    def auto_noise_addition(self, levels, constraints):\n",
    "#         select the random users and their behaviour with random latency\n",
    "        self.noisy_tariff[\"h1_start\"] = [random.choice(range(constraints[\"h1_start\"]-2, \n",
    "                                                             constraints[\"h1_start\"]+int(trials_.duration/2))) for _ in range(len(self.avail_users))]\n",
    "        self.noisy_tariff[\"h1_end\"] = [random.choice(range(constraints[\"h1_end\"]-int(trials_.duration/2), \n",
    "                                                           constraints[\"h1_end\"]+2)) for _ in range(len(self.avail_users))]\n",
    "    \n",
    "\n",
    "    def tariff_policy(self, levels, constraints):\n",
    "#         use variables from auto_noise_addition and input variables of this function to create a tariff policy \n",
    "#         for each participating user **Needs more attention\n",
    "        self.auto_noise_addition(levels,constraints)\n",
    "    \n",
    "        self.d = np.ones((48, len(self.avail_users)))\n",
    "        self.df_tariff = pd.DataFrame(data=self.d, columns = self.avail_users)\n",
    "        for i in range(len(self.avail_users)):\n",
    "            self.df_tariff.loc[self.noisy_tariff[\"h1_start\"][i]:self.noisy_tariff[\"h1_end\"][i], self.avail_users[i]] = 2\n",
    "\n",
    "        self.df_tariff.index = self.sample.index\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "#         FOR EACH USER, call test function of consumption model, get modified behaviour, return original data point and modified data point\n",
    "        self.sample = self.sample.interpolate(method = 'linear', axis = 0).ffill().bfill()\n",
    "        self.sample = self.sample.join(self.df_weather.loc[self.sample.index,:])\n",
    "        df_response = pd.DataFrame()\n",
    "        self.sample[\"hour\"] = self.sample.index.hour\n",
    "        self.sample[\"day\"] = self.sample.index.day\n",
    "        self.sample[\"month\"] = self.sample.index.month\n",
    "        \n",
    "        list_ = [i for i in range(len(self.avail_users))]\n",
    "\n",
    "        for i in list_:\n",
    "            one_hot= pd.get_dummies(self.df_tariff[self.avail_users[i]])\n",
    "            one_hot_renamed = one_hot.rename(index=str, columns={1.0:'normal', 2.0:'high', 3.0:'low'}) \n",
    "            self.sample = pd.concat([self.sample, one_hot_renamed], axis =1)\n",
    "            self.sample[\"low\"] = 0\n",
    "\n",
    "            self.sample[\"trial_n\"] = self.sample[self.avail_users[i]]\n",
    "            \n",
    "#             consumption_model.test(self.sample[self.params['X_variables']], one_hot_renamed)\n",
    "            self.test()\n",
    "#             df_response[self.avail_users[i]] = consumption_model.preds\n",
    "            df_response[self.avail_users[i]] = self.preds\n",
    "            self.sample = self.sample.drop(['low', 'normal', 'high', 'trial_n'], axis= 1)\n",
    "            \n",
    "        df_response['response']= df_response.mean(axis = 1)\n",
    "        return df_response['response']\n",
    "            \n",
    "            \n",
    "            \n",
    "    def test(self):\n",
    "        self.preds = self.sample['trial_n']\n",
    "        self.preds.loc[self.sample['high']==1] = self.preds.loc[self.sample['high']==1]*0.9 #(1 - 9/(100*self.params['active_users']*self.params['avail_users']))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learner\n",
    "The following cell simulates the real-world scenario to mimic the practical trials. The only difference is that the dates are randomly selected rather than sequentially moving in time. \n",
    "\n",
    "The following algorithm gets the features set for the next datapoint and based on the knowledge of the historical feature subspace, it then takes a decision about the 'need' of an labelling experiment. That is, if the situation is rare in the historical data, the learner will give it more importance as it contains more information (Information theory says that the probability of occurance of a symbol is inversely proportional to the infomation contained in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activeLearner(object):\n",
    "    \n",
    "    def __init__(self, df_n, df_weath, params):\n",
    "        self.df_n = df_n\n",
    "        self.df_weather = df_weath\n",
    "        self.params = params\n",
    "        self.y_pred = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.counter = 0\n",
    "        self.iter = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    def sample_stream(self):\n",
    "        \n",
    "        #Randomly select next data point\n",
    "        sim.random_day()\n",
    "        level, constraints = trials_.get_random_tariff()\n",
    "        sim.tariff_policy(level, constraints)\n",
    "            \n",
    "        response = sim.run()          \n",
    "        expected = sim.sample[sim.avail_users].mean(axis = 1).values\n",
    "         \n",
    "        dayofweek, month, hourofday, season = self.get_features()\n",
    "            \n",
    "        data = {'expected':expected, \n",
    "                'response':response.values, \n",
    "                'dow':dayofweek, \n",
    "                'season':season,\n",
    "                'hod': hourofday,\n",
    "                'month': month}\n",
    "        \n",
    "        df_ = pd.DataFrame(data, index=response.index)\n",
    "        df = pd.concat([df_,self.df_weather.loc[sim.timestamp,:]], axis=1)\n",
    "\n",
    "#         print(\"sample_stream \", df.columns)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_random_samples(self):\n",
    "        temp_df = pd.DataFrame(columns = ['expected', \n",
    "                                          'response', \n",
    "                                          'dow', \n",
    "                                          'season'])\n",
    "        \n",
    "        \n",
    "#         select first random day of 48 data points\n",
    "        sim.random_day()\n",
    "        \n",
    "#         Add contextual data in future for the particular day to self.df\n",
    "        \n",
    "    \n",
    "#         Generate new tariff signals for one day\n",
    "        level, constraints = self.get_random_tariff()\n",
    "        \n",
    "#         Get schocastic behaviour of users\n",
    "        sim.tariff_policy(level, constraints)\n",
    "    \n",
    "    \n",
    "        response = sim.run()\n",
    "                \n",
    "        expected = sim.sample[sim.avail_users].mean(axis = 1).values\n",
    "        \n",
    "        dayofweek, month, hourofday, season = self.get_features()\n",
    "            \n",
    "        data = {'expected':expected, \n",
    "                'response':response.values, \n",
    "                'dow':dayofweek, \n",
    "                'season':season,\n",
    "                'hod': hourofday,\n",
    "                'month': month}\n",
    "\n",
    "        df_ = pd.DataFrame(data, index=response.index)\n",
    "        self.df = pd.concat([df_,self.df_weather.loc[sim.timestamp,:]], axis=1)\n",
    "\n",
    "            \n",
    "#        Create n number of datapoints from simulator (n=self.params[\"init_samples\"])\n",
    "#        Create a list of 1 to n to include a progress bar\n",
    "        \n",
    "        list_ = [i for i in range(self.params[\"init_samples\"])]\n",
    "\n",
    "        for i in tqdm(list_):\n",
    "            \n",
    "            sim.random_day()\n",
    "            \n",
    "#             Decide the tariff signal and stochastic behaviour of users around that tariff signal\n",
    "            level, constraints = self.get_random_tariff()\n",
    "            sim.tariff_policy(level, constraints)\n",
    "            \n",
    "            response = sim.run()\n",
    "            \n",
    "            expected = sim.sample[sim.avail_users].mean(axis = 1).values\n",
    "            \n",
    "            dayofweek, month, hourofday, season = self.get_features()\n",
    "            \n",
    "            data = {'expected':expected, \n",
    "                    'response':response.values, \n",
    "                    'dow':dayofweek, \n",
    "                    'season':season,\n",
    "                    'hod': hourofday,\n",
    "                    'month': month}\n",
    "            \n",
    "            \n",
    "        \n",
    "            df_ = pd.DataFrame(data, index=response.index)\n",
    "            temp_df = pd.concat([df_,self.df_weather.loc[sim.timestamp,:]], axis=1)\n",
    "            self.df = pd.concat([self.df, temp_df], axis=0, sort=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def split_data(self, df):\n",
    "        \n",
    "        X_train = df[self.params['X_var_activeL']]\n",
    "        y_train = df[self.params['y_var_activeL']]\n",
    "\n",
    "        return X_train, y_train\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_features(self):\n",
    "        try:\n",
    "#             get day of week encoding\n",
    "            dayofweek = sim.sample.index.dayofweek\n",
    "#             get month of year encoding\n",
    "            month = sim.sample.index.month\n",
    "#             get hour of day value from timestamp\n",
    "            hourofday = sim.sample.index.hour\n",
    "#             we are more interested in season based behaviour than monthly behaviour\n",
    "                \n",
    "            season = [0 if x in [3,4,5] else x for x in month]\n",
    "            season = [1 if x in [6,7,8] else x for x in season]\n",
    "            season = [2 if x in [9,10,11] else x for x in season]\n",
    "            season = [3 if x in [1,2,12] else x for x in season]\n",
    "            \n",
    "            \n",
    "            \n",
    "                       \n",
    "        except Exception as e: print(e)    \n",
    "\n",
    "        return dayofweek, month, hourofday, season\n",
    "                     \n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.regres = RandomForestRegressor(max_depth=10, \n",
    "                                                random_state=0, \n",
    "                                                n_estimators=1000)\n",
    "        self.regres.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test, y_test):\n",
    "        exp_id = self.get_experiment_id()\n",
    "        self.y_pred.loc[:, exp_id] = self.regres.predict(X_test)\n",
    "        self.y_test.loc[:, exp_id] = y_test.values\n",
    "        mse = self.get_error_measure(y_test, self.y_pred)\n",
    "        \n",
    "    \n",
    "    def get_error_measure(self, y_test, y_pred):\n",
    "        mse = ((y_test - y_pred)**2).mean(axis=0)\n",
    "        return mse\n",
    "    \n",
    "                     \n",
    "    def get_experiment_id(self):\n",
    "        exp_available = self.params[\"total_experiments\"] - self.params[\"init_samples\"]\n",
    "        \n",
    "        if self.counter > exp_available:\n",
    "            self.counter=0\n",
    "            self.iter = self.iter + 1\n",
    "            \n",
    "        exp_count = str(self.counter)\n",
    "        iter_count = str(self.iter)\n",
    "        exp_id = \"iter\" + iter_count + \"_exp\" + exp_count\n",
    "        self.counter = self.counter + 1\n",
    "        return exp_id\n",
    "       \n",
    "    def get_random_tariff(self):\n",
    "        self.year = random.randrange(2012,2013)\n",
    "        self.month = random.randrange(1,12)\n",
    "        self.day = random.randrange(1,28)\n",
    "        self.hour = random.randrange(17,18)\n",
    "        self.minute = random.choice([0,30])\n",
    "        self.duration = random.randrange(6, 8)\n",
    "        index = datetime(self.year, self.month, self.day, self.hour, self.minute, 0)\n",
    "        h1_start = int(index.hour * 2) + int(index.minute / 30) \n",
    "        h1_end = h1_start + self.duration\n",
    "        constraints = {\"h1_start\": h1_start, \"h1_end\": h1_end}\n",
    "        level = 0       #dummy\n",
    "        return level, constraints\n",
    "        \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "    def run(self):\n",
    "        \n",
    "        self.df = pd.DataFrame(columns = ['expected', \n",
    "                                          'response', \n",
    "                                          'dow', \n",
    "                                          'season',\n",
    "                                          'month',\n",
    "                                          'hod'])\n",
    "        \n",
    "        self.get_random_samples()\n",
    "                \n",
    "        X_train, y_train= self.split_data(self.df)\n",
    "        self.train_model(X_train, y_train)\n",
    "        mse = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        list_ = [i for i in range(self.params[\"total_experiments\"] - self.params[\"init_samples\"])]\n",
    "        for exp in tqdm(list_):\n",
    "            \n",
    "            next_sample = self.sample_stream()\n",
    "            X_test, y_test= self.split_data(next_sample)\n",
    "            self.predict(X_test, y_test)\n",
    "            self.df = pd.concat([self.df, next_sample], axis=0, sort=True)\n",
    "            X_train, y_train= self.split_data(self.df)\n",
    "            self.train_model(X_train, y_train)\n",
    "            \n",
    "                     \n",
    "        return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    try:\n",
    "        print(\"Reading aggregate consumption data...\")\n",
    "        df=pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/mod_datasets/aggregate_consumption.csv', sep=',', header=0, index_col=0, parse_dates=['GMT'], low_memory=False)\n",
    "        df = df.drop_duplicates()\n",
    "        print(\"Done\")\n",
    "        print(\"Reading weather data...\")\n",
    "        df_midas=pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/mod_datasets/midas_weather.csv', sep=',', header=0, index_col=0, parse_dates=['GMT'], low_memory=False)\n",
    "        df_midas_rs = df_midas.resample('30T').mean()\n",
    "        df_interpolated = df_midas_rs.interpolate(method='linear')\n",
    "        df_weather = df_interpolated.loc['2013-01':'2013-12',:]\n",
    "        df_final = pd.concat([df,df_weather], axis=1)\n",
    "        print(\"Done\")\n",
    "        print(\"Reading LCL consumption data...\")\n",
    "        df_n=pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/UKDA-7857-csv/csv/data_collection/data_tables/consumption_n.csv', sep=',', header=0, index_col=0, parse_dates=['GMT'], low_memory=False)\n",
    "        df_n = df_n.drop_duplicates()\n",
    "        df_weath = df_interpolated.copy()\n",
    "        print(\"Done\")\n",
    "        \n",
    "    except Exception as e: print(e)\n",
    "        \n",
    "    return df_final, df_n, df_weath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init():\n",
    "    df_final, df_n, df_weath = import_data()\n",
    "    \n",
    "    try:\n",
    "        cons_model = ConsumptionModel(df_final, params)\n",
    "        sim = Simulator(df_n.loc['2012-05':, :], df_weath.loc['2012-05':, :], params)\n",
    "        trials_ = activeLearner(df_n.loc['2012-05':, :], df_weath.loc['2012-05':, :], params)\n",
    "        \n",
    "    except Exception as e: print(e)    \n",
    "    \n",
    "    return cons_model, sim, trials_#, selectsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bokeh(y, x, title, xlabel, ylabel):\n",
    "    output_notebook()\n",
    "    file_name = \"../temp/\" + title + \".html\"\n",
    "    output_file(file_name) #Uncom`ment it to save the plot in html file\n",
    "    \n",
    "\n",
    "    p=figure(plot_width=800, plot_height=400, title = title, x_axis_label = xlabel, y_axis_label = ylabel,)\n",
    "    p.line(x, y, line_width=1, color='blue')\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     # import data and declare classes\n",
    "    cons_model, sim, trials_= _init()\n",
    "\n",
    "#     # start the simulator and active learning by membership query synthesis\n",
    "\n",
    "    trials_.run()\n",
    "    list_ = [i for i in range(len(mse))]\n",
    "    d = {'0':mse}\n",
    "    \n",
    "    for i in range(params[\"total_iterations\"]):\n",
    "        print(\"Iteration\", i+1) \n",
    "        trials_.run()\n",
    "    \n",
    "    \n",
    "#     title = \"Mean Squared Error vs Number of samples\"\n",
    "#     xlabel = \"Number of iterations\"\n",
    "#     ylabel = \"MSE\"\n",
    "#     list_ = [i for i in range(params[\"total_experiments\"])]\n",
    "    \n",
    "#     plot_bokeh(mse_total.mean(axis=1), list_, title, xlabel, ylabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    today = date.today()\n",
    "\n",
    "    \n",
    "    file_name = \"../results/generated_data\" + str(today) + \".csv\"\n",
    "    trials_.df.to_csv(file_name, sep='\\t')\n",
    "        \n",
    "    file_name = \"../results/predictions\" + str(today) + \".csv\"\n",
    "    trials_.y_pred.to_csv(file_name, sep='\\t')\n",
    "    \n",
    "    file_name = \"../results/actuals\" + str(today) + \".csv\"\n",
    "    trials_.y_test.to_csv(file_name, sep='\\t')\n",
    "    \n",
    "    file_name = \"../results/feature_set\" + str(today) + \".txt\"\n",
    "    with open(file_name, \"w\") as output:\n",
    "        output.write(str(params[\"X_var_activeL\"]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch book\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # start the simulator and active learning by membership query synthesis\n",
    "    mse_ActiveL, mse_Rand = trials_.run()\n",
    "    list_ = [i for i in range(len(mse_ActiveL))]\n",
    "    d1 = {'0':mse_ActiveL}\n",
    "    mse_AL_total = pd.DataFrame(data=d1)\n",
    "    d2 = {'0':mse_Rand}\n",
    "    mse_Rand_total = pd.DataFrame(data=d2)\n",
    "    \n",
    "    for i in range(50):\n",
    "        mse_ActiveL, mse_Rand = trials_.run()\n",
    "        mse_AL_total.loc[:,str(i+1)] = mse_ActiveL\n",
    "        mse_Rand_total.loc[:, str(i+1)] = mse_Rand\n",
    "        \n",
    "    plot_bokeh(mse_AL_total.mean(axis=1), mse_Rand_total.mean(axis=1), params, list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectSample(object):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        \n",
    "    def from_oracle(self, preds, X_test, y_test):\n",
    "        #Select the point with maximum error\n",
    "        df_y_test = y_test.reset_index()\n",
    "        d = {'preds': preds}\n",
    "        df_preds = pd.DataFrame(data = d)\n",
    "        df_X_test = X_test.reset_index()\n",
    "        \n",
    "        error_ = (df_y_test['response']-df_preds['preds'])**2\n",
    "        \n",
    "        mse = ((df_y_test['response']-df_preds['preds'])**2).mean(axis=0)\n",
    "        \n",
    "        self.params[\"day_of_week\"] = df_X_test.loc[error_.idxmax(),'dow']\n",
    "        self.params[\"season\"] = df_X_test.loc[error_.idxmax(),'season']\n",
    "        \n",
    "        # Generate new data point for above dow and season\n",
    "        \n",
    "        sim.select_day()\n",
    "        level, constraints = trials_.get_random_tariff()\n",
    "        sim.tariff_policy(level, constraints)\n",
    "            \n",
    "        response = sim.run()\n",
    "        response_max = response.max()\n",
    "          \n",
    "        expected = sim.sample[sim.avail_users].mean(axis = 1).values\n",
    "        expected_max = expected.max()\n",
    "          \n",
    "        dow, season = trials_.get_features()\n",
    "    \n",
    "        df = pd.DataFrame(columns = ['expected', 'response', 'dow', 'season'])\n",
    "        df.loc[0] = [expected_max, response_max, dow, season]\n",
    "        return df, mse\n",
    "        \n",
    "    def random(self):\n",
    "        #Randomly select next data point\n",
    "        sim.random_day()\n",
    "        level, constraints = trials_.get_random_tariff()\n",
    "        sim.tariff_policy(level, constraints)\n",
    "            \n",
    "        response = sim.run()\n",
    "        response_max = response.max()\n",
    "          \n",
    "        expected = sim.sample[sim.avail_users].mean(axis = 1).values\n",
    "        expected_max = expected.max()\n",
    "          \n",
    "        dow, season = trials_.get_features()\n",
    "    \n",
    "        df = pd.DataFrame(columns = ['expected', 'response', 'dow', 'season'])\n",
    "        df.loc[0] = [expected_max, response_max, dow, season]\n",
    "        return df, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/results/actuals2019-04-20.csv', sep='\\t', low_memory=False)\n",
    "df2 = df = pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/results/predictions2019-04-20.csv', sep='\\t', low_memory=False)\n",
    "df1-df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bokeh2(y1, y2, x, title, xlabel, ylabel):\n",
    "    output_notebook()\n",
    "    file_name = \"../temp/\" + title + \".html\"\n",
    "    output_file(file_name) #Uncom`ment it to save the plot in html file\n",
    "    \n",
    "\n",
    "    p=figure(plot_width=800, plot_height=400, title = title, x_axis_label = xlabel, y_axis_label = ylabel,)\n",
    "    p.line(x, y1, line_width=1, color='blue')\n",
    "    p.line(x, y2, line_width=1, color='red')\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.mean(axis = 1)\n",
    "title = \"Actual and predictions\"\n",
    "xlabel = \"half hour slots\"\n",
    "ylabel = \"energy consumption\"\n",
    "list_ = [i for i in range(48)]\n",
    "\n",
    "plot_bokeh2(df1[\"iter1_exp800\"].values, df2[\"iter1_exp804\"].values, list_, title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate.experiment()\n",
    "# level, constraints = generate.tariff()\n",
    "# sim.tariff_policy(level, constraints)\n",
    "# response = sim.run()\n",
    "# response\n",
    "\n",
    "a = trials_.y_test.reset_index()\n",
    "d = {'preds': trials_.preds}\n",
    "b = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/results/actuals2019-04-19.csv', sep='\\t', low_memory=False)\n",
    "df2 = df = pd.read_csv('~/Documents/work/Active-Learning-TUD-Thesis/results/predictions2019-04-19.csv', sep='\\t', low_memory=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
