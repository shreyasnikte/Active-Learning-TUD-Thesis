{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design of smart dToU policy using machine learning \n",
    "#### A DSM approach to achieve maximum savings with minimum active users\n",
    "---\n",
    "\n",
    "## The Idea\n",
    "The proposed idea approaches the demand side management problem using smart dToU policy to further improve the user engagement. The idea is to design a tariff policy which would match the observed mean consumption to target mean consumption. While improving the tariff policy, the algorithm will also create a distribution of the users based on their engagement as well as their influence on overall consumption. The target outcome of the experiment is to get the least number of tariff signals to be sent to specific users in order to match the target mean consumption. \n",
    "\n",
    "For the aforementioned experimental setup, based on their engagement, the users are categorized as follows:\n",
    "\n",
    "1. Users with more than 95% engagement\n",
    "2. Users with more than 60% engagement\n",
    "3. Users with more than 30% engagement\n",
    "4. Users with no engagement\n",
    "\n",
    "The above categories are proposed for initial ideation and may change over time.\n",
    "\n",
    "### Experiment constraints\n",
    "- Upper limit on the number of test signals:\n",
    "   - For each experimental setup, only limited number of test signals will be provided.\n",
    "   - The algorithm can decide the number of recipients for each test signal.\n",
    "   \n",
    "   \n",
    "- Importance weighting for tariff hours:\n",
    "    - For example, higher weights will be given to 'high tariff' during the common peak hours\n",
    "    \n",
    "## Problem details\n",
    "\n",
    "The problem is two fold. The first step of the problem is to identify best tariff policy from the given set of tariff policies. The next and more interesting problem is to minimize the number of tariff signals to be sent for a particular trial.\n",
    "\n",
    "### Why Bayesian analysis\n",
    "Although the experiment design for dToU tariff policy design is a simple problem (because of known and predictable peak hours), complexity of problem increases when we try to minimize the total number of signals to be sent. At this point, the problem can be analysed from two different views: \n",
    "1. Frequentist problem (classic way of machine learning) \n",
    "2. Bayesian problem\n",
    "\n",
    "The Bayesian analysis is superior to classic frequentist analysis becuase of the following advantages:\n",
    "1. Use of priors. Therefore easier to compensate the shift in the target variable (idea of 'target shift' seems more important in this case than 'covariate shift'. Explained in later section)\n",
    "2. Bayesian analysis tells us how likely 'A' is winner over 'B' and by how much. This improves the transparency in the decision making process for energy retailer company in practical world. Frequentist problem depends entirely on the prespecified hypothesis.\n",
    "3. Bayesian analysis doe not require user to define many hyperparameters/ thresholds to formulate valid hypothesis. Hence, robustness and reliability of the algorithm is better. This is especially useful in this case as the entire hypothesis formulation depends on simulation data. Therefore, ideally models with Bayesian inference would perform better in practical world.\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "Both the problems will be solved with active learning method. The first problem can be solved with frequentist analysis and hypothesis (solution can be converged easily with preset of tariff policies). Hence, the tariff policy choosing problem can be solved with any available probablistic method.\n",
    "\n",
    "For choosing the optimal number of tariff signals to specific users (prioritized by algorithm) for meeting the target consumption level, bayesian analysis is used. The Bayes rule for this particular problem can be formulated as below,\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\rho | \\theta(Y_t,c_t))&=\\frac{p(\\theta(Y_t,c_t)|\\rho)*p(\\rho)}{p(\\theta(Y_t,c_t))}\n",
    "\\end{align}$$\n",
    "\n",
    "Where,\n",
    "$$\n",
    "\\begin{align}\n",
    "Y_t &= \\text{Expected mean consumption} \\\\\n",
    "c_t &= \\text{Target mean consumption}  \\\\\n",
    "\\theta(Y_t,c_t) &= \\text{Complex function of $Y_t$ and $c_t$} \\\\\n",
    "\\rho &= \\text{Vector of contribution of $k$ users in total consumption change, where $\\rho \\in (p_1,p_2,...,p_k)$}\n",
    "\\end{align}$$\n",
    "\n",
    "The above Bayesian approach directly uses the simulator generated 'observation' as expected mean consumption. A more practical approach would be the use of contextual variables. The tartget mean consumption will be provided to the model from preset targets. The œÅ is the distribution of contribution of k users in total energy consumption change.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
